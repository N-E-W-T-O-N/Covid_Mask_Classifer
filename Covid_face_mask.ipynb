{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid-face-mask",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "092PPskRZujA"
      },
      ,
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY-SpG6tbPXc"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"*********\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"************\" # key from the json file\n",
        "!kaggle datasets download -d prithwirajmitra/covid-face-mask-detection-dataset # api copied from kaggle\n",
        "!unzip -qq covid-face-mask-detection-dataset.zip\n",
        "!rm -r covid-face-mask-detection-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzO1O23fbPiR"
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D , Dropout , Flatten , Dense \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlOkvH3FdEiH"
      },
      "source": [
        "main_dir = \"/content/New Masks Dataset\"\n",
        "train_dir = \"/content/New Masks Dataset/Train\"\n",
        "test_dir = \"/content/New Masks Dataset/Test\"\n",
        "valid_dir = \"/content/New Masks Dataset/Validation\"\n",
        " \n",
        "train_mask_dir = os.path.join(train_dir,\"Mask\")\n",
        "train_nonmask_dir = os.path.join(train_dir,\"Non Mask\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttEJPOzMbPvb"
      },
      "source": [
        "train_mask_name = os.listdir(train_mask_dir)\n",
        "print(train_mask_name[:20])\n",
        " \n",
        "train_nonmask_name = os.listdir(train_nonmask_dir)\n",
        "print(train_nonmask_name[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbnoefKbbQCT"
      },
      "source": [
        "import random\n",
        "nrows = 5\n",
        "ncols = 5\n",
        "plt.figure(figsize=(12,12))\n",
        " \n",
        "mask_pic=[]\n",
        "for i in train_mask_name[0:10]:\n",
        "    mask_pic.append(os.path.join(train_mask_dir,i))\n",
        "    \n",
        "nonmask_pic = []    \n",
        "for i in train_nonmask_name[0:10]:\n",
        "    nonmask_pic.append(os.path.join(train_nonmask_dir,i))\n",
        "    \n",
        "print(mask_pic)\n",
        "print(nonmask_pic)\n",
        " \n",
        "merge_list = mask_pic+nonmask_pic\n",
        "random.shuffle(merge_list)\n",
        "for i in range(0 , len(merge_list)):\n",
        "    data=merge_list[i].split('/',4)[4]\n",
        "    sp = plt.subplot(nrows,ncols,i+1)\n",
        "    sp.axis('Off')\n",
        "    image = mpimg.imread(merge_list[i])\n",
        "    sp.set_title(data,fontsize = 10)\n",
        "    plt.imshow(image,cmap='gray')\n",
        "    \n",
        "plt.show()    \n",
        "image=mpimg.imread(merge_list[1])\n",
        "image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRsrkEj5bQO_"
      },
      "source": [
        " \n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  zoom_range = 0.1,\n",
        "                                  rotation_range=39,\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=False,\n",
        "                                  )\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "train_datagen = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size=(200,200),\n",
        "                                                 batch_size =36 , #how much image is insert at a time\n",
        "                                                 class_mode='binary'#what type of classification is\n",
        "                                                 )\n",
        " \n",
        "test_datagen = test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(200,200),\n",
        "                                                 batch_size =36 , #how much image is insert at a time\n",
        "                                                 class_mode='binary'#what type of classification is\n",
        "                                                 )\n",
        " \n",
        "valid_datagen = valid_datagen.flow_from_directory(valid_dir,\n",
        "                                                 target_size=(200,200),\n",
        "                                                 batch_size =36 , #how much image is insert at a time\n",
        "                                                 class_mode='binary'#what type of classification is\n",
        "                                                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcAAg7AhbQXJ"
      },
      "source": [
        "train_datagen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69GAIjglR6y"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import  *\n",
        "first=InceptionV3(input_shape=(200,200,3),include_top=False,weights='imagenet')\n",
        "for layer in first.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "#first.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjc4H27vmOWM"
      },
      "source": [
        "\n",
        "#x=MaxPooling2D(pool_size=(2,2))(first.output)\n",
        "#x=Dropout(0.4)(x)\n",
        "\n",
        "x=layers.Flatten()(first.output)\n",
        "x=layers.Dense(250,activation='relu')(x)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "x=layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(first.input,x)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoybS40ubQtP"
      },
      "source": [
        "model.compile(Adam(lr=0.001),\n",
        "              loss='binary_crossentropy'\n",
        "              ,metrics='accuracy')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyCtgBLAbQ8E"
      },
      "source": [
        "history=model.fit(train_datagen,\n",
        "                 epochs=30,\n",
        "                 validation_data=valid_datagen\n",
        "                 )\n",
        " \n",
        "N = np.arange(0, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6T_q_pZfzlT"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/model.h5\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8UxvGsNbRJo"
      },
      "source": [
        "plt.plot(N,history.history['loss'])\n",
        "plt.plot(N,history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.savefig(\"Loss.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd17Ytu_bRXY"
      },
      "source": [
        "plt.plot(N,history.history['accuracy'])\n",
        "plt.plot(N,history.history['val_accuracy'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.savefig(\"Accuracy.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxiQcotqbRhW"
      },
      "source": [
        "test_loss , test_acc = model.evaluate(test_datagen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePjI_IBObRrd"
      },
      "source": [
        "print(test_loss)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk6nKa9XcvKh"
      },
      "source": [
        "#if you want to upload\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        " \n",
        "uploaded = files.upload()\n",
        "for fname in uploaded.keys():\n",
        "  img_path='/content/'+fname\n",
        "  img = image.load_img(img_path , target_size=(150,150))\n",
        "  images = image.img_to_array(img)\n",
        "  images=np.expand_dims(images,axis=0)\n",
        "  prediction = model.predict(images)\n",
        "  print(fname)\n",
        "  if prediction==0:\n",
        "    print('mask')\n",
        "  else:\n",
        "    print('nomask')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPI47yZwTn8V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
